---
layout: post
title: Expectation Maximization
categories: ml
tags: EM, Expectation Maximization
---

### Introduction

给定数据 $X$，一种常用的估计模型参数 $\theta$ 的方法是 maximum likelihood，即：

$$\theta = \underset{\theta}{\arg\max} \;\; p(X|\theta)$$

这里的 $X$ 是我们可见的，即 visible variable。如果给定的问题涉及到 hidden variable，ML 就需要引入新变量，即：

$$\theta = \underset{\theta}{\arg\max} \;\; p(X|\theta) = \underset{\theta}{\arg\max} \;\; \int p(X, z|\theta) dz$$

其中 $z$ 对应 hidden variable。在很多情况下，引入积分后问题会变得不可求解，这也是为什么需要 EM 算法的原因。EM 尝试用迭代的方式去求解 $\theta$，从而避免掉积分操作。

另外，为了计算方便，我们通常并不直接操作 $p(X|\theta)$，而是用 $\log$ 形式代替，即：

$$\theta = \underset{\theta}{\arg\max} \; \log p(X|\theta)$$

为了使用方便，下面记 $L(\theta) = \log p(X|\theta)$

### EM Iteration

假设第 $n$ 轮迭代得到的参数是 $\theta\_n$，由于我们的目标是最大化 $L(\theta)$，因此我们希望下一轮迭代得到的 $\theta$ 可以进一步提升 $L(\theta)$。换句话说，在第 $n+1$ 轮迭代时，希望能找到 $\theta$ 使得 $L(\theta) > L(\theta\_n)$。

首先明确一点，我们不可能通过直接优化 $L(\theta) - L(\theta\_n)$ 得到下一轮的 $\theta$，因为优化 $L(\theta) - L(\theta\_n)$ 等价于优化 $L(\theta)$ ($L(\theta\_n)$是常数，在优化中不起作用)，这个前面已经说了不好优化，好优化就不用 EM 算法了。为了得到一个更好的 $\theta$， **EM 算法的做法是先得到 $L(\theta) - L(\theta\_n)$ 的一个下界，然后去优化这个下界来得到一个更优的 $\theta$** 。

下面的推导首先给出 $L(\theta) - L(\theta\_n)$ 的下界并证明可以通过优化这个下界得到更优的 $\theta$。

推导过程中用到了 concave function 的一个性质：

<blockquote>
if $f(x)$ is a concave function，$\forall \sum_i a_i = 1 \;\; f(\sum_{i}a_i x_i) \geq \sum_i a_i f(x_i)$
</blockquote>

特别的，如果 $f(x) = \log x$，则有 $\log \sum\_i a\_i x\_i \geq \sum\_i a\_i \log x\_i \;\; \forall \sum\_i a\_i = 1$

### PLSA


